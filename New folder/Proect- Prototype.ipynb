{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Project Title: Twitter Sentiment Analysis for EABL Brands\n",
    "\n",
    "Objective:\n",
    "To analyze and understand the sentiment of Twitter users towards EABL's brands using Natural Language Processing (NLP) techniques.\n",
    "\n",
    "Project Steps:\n",
    "\n",
    "Data Collection:\n",
    "Use the Twitter API to gather tweets related to EABL's brands (e.g., Tusker Lager, Johnnie Walker, etc.).\n",
    "Store the data in a suitable format (e.g., CSV or JSON)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example code for Twitter data collection using Tweepy\n",
    "import tweepy\n",
    "import pandas as pd\n",
    "\n",
    "# Set up Twitter API credentials\n",
    "consumer_key = 'your_consumer_key'\n",
    "consumer_secret = 'your_consumer_secret'\n",
    "access_token = 'your_access_token'\n",
    "access_token_secret = 'your_access_token_secret'\n",
    "\n",
    "# Authenticate with Twitter API\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True)\n",
    "\n",
    "# Search for tweets related to EABL brands\n",
    "tweets = tweepy.Cursor(api.search, q='EABL', lang='en').items(100)\n",
    "\n",
    "# Create a DataFrame to store the tweets\n",
    "tweet_data = pd.DataFrame(data=[tweet.text for tweet in tweets], columns=['Tweet'])\n",
    "tweet_data.to_csv('eabl_tweets.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Preprocessing:\n",
    "Clean the tweets by removing irrelevant information (e.g., URLs, mentions, special characters).\n",
    "Tokenize the text and perform stemming or lemmatization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example code for data preprocessing\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "# Load NLTK stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Preprocess tweets\n",
    "def preprocess_tweet(tweet):\n",
    "    # Remove URLs, mentions, and special characters\n",
    "    tweet = re.sub(r'http\\S+|www\\S+|@\\w+|#\\w+|[^\\w\\s]', '', tweet)\n",
    "    # Tokenize and remove stopwords\n",
    "    tokens = [word for word in word_tokenize(tweet) if word.lower() not in stop_words]\n",
    "    # Perform stemming\n",
    "    stemmer = PorterStemmer()\n",
    "    tokens = [stemmer.stem(word) for word in tokens]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Apply preprocessing to the DataFrame\n",
    "tweet_data['Cleaned_Tweet'] = tweet_data['Tweet'].apply(preprocess_tweet)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentiment Analysis:\n",
    "Use pre-trained models or train a sentiment analysis model on the cleaned data.\n",
    "Evaluate the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example code for sentiment analysis using TextBlob\n",
    "from textblob import TextBlob\n",
    "\n",
    "# Analyze sentiment using TextBlob\n",
    "tweet_data['Sentiment'] = tweet_data['Cleaned_Tweet'].apply(lambda x: TextBlob(x).sentiment.polarity)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Evaluation:\n",
    "Split the data into training and testing sets.\n",
    "Train and evaluate the sentiment analysis model using metrics such as accuracy, precision, recall, and F1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example code for model evaluation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(tweet_data['Cleaned_Tweet'], tweet_data['Sentiment'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a pipeline with CountVectorizer and Multinomial Naive Bayes\n",
    "model = make_pipeline(CountVectorizer(), MultinomialNB())\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recommendation and Conclusion:\n",
    "Based on the analysis, provide recommendations for improving brand perception or customer engagement on social media.\n",
    "Conclude the project by summarizing key findings and the effectiveness of the sentiment analysis model.\n",
    "This project will give you insights into how people perceive EABL's brands on Twitter and help you make data-driven recommendations for brand management.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
